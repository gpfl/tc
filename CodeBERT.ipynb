{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CodeBERT"
      ],
      "metadata": {
        "id": "LxRKZ82nkiVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mon Dec  6 19:16:24 2021       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 00000001:00:00.0 Off |                    0 |\r\n| N/A   33C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6134ZzGCntbf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1638810837599,
          "user_tz": 180,
          "elapsed": 342,
          "user": {
            "displayName": "Gustavo Flores",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjxNVr_7UdeGpTG8rXW6NPC2VVtbM9-yV2jnccHHg=s64",
            "userId": "07460781209050067384"
          }
        },
        "outputId": "c41dc364-944f-4295-a65a-47b57472dac8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "'cuda'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SY33XO1bLeWt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1638810845167,
          "user_tz": 180,
          "elapsed": 5559,
          "user": {
            "displayName": "Gustavo Flores",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjxNVr_7UdeGpTG8rXW6NPC2VVtbM9-yV2jnccHHg=s64",
            "userId": "07460781209050067384"
          }
        },
        "outputId": "a2da4c83-3005-415c-dae3-c2f6f31959fc",
        "gather": {
          "logged": 1638818199233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "4GQdOVnyoNlU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1638810865336,
          "user_tz": 180,
          "elapsed": 3136,
          "user": {
            "displayName": "Gustavo Flores",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjxNVr_7UdeGpTG8rXW6NPC2VVtbM9-yV2jnccHHg=s64",
            "userId": "07460781209050067384"
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount GDrive"
      ],
      "metadata": {
        "id": "WV_0TkzhmfMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/teslak80code/code/Users/GUSTAVO.PEREIRA87'\n",
        "DATA_PATH = DRIVE_PATH + '/codesummarization_data'"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "mhQItdCNs_HR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1638810865337,
          "user_tz": 180,
          "elapsed": 8,
          "user": {
            "displayName": "Gustavo Flores",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjxNVr_7UdeGpTG8rXW6NPC2VVtbM9-yV2jnccHHg=s64",
            "userId": "07460781209050067384"
          }
        },
        "gather": {
          "logged": 1638818220072
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/teslak80code/code/Users/GUSTAVO.PEREIRA87/codesummarization_data'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638818279676
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone CodeBert repo"
      ],
      "metadata": {
        "id": "H4nESz_vml0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/guoday/CodeBERT.git"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Cloning into 'CodeBERT'...\nremote: Enumerating objects: 51, done.\u001b[K\nremote: Counting objects: 100% (51/51), done.\u001b[K\nremote: Compressing objects: 100% (49/49), done.\u001b[K\nremote: Total 51 (delta 7), reused 35 (delta 2), pack-reused 0\u001b[K\nUnpacking objects: 100% (51/51), done.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fJ-XfjQmsOA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1638810887243,
          "user_tz": 180,
          "elapsed": 4942,
          "user": {
            "displayName": "Gustavo Flores",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjxNVr_7UdeGpTG8rXW6NPC2VVtbM9-yV2jnccHHg=s64",
            "userId": "07460781209050067384"
          }
        },
        "outputId": "4fa6a81b-83fc-4a95-db27-f492c6bb25aa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tune"
      ],
      "metadata": {
        "id": "WiIl-avhk79r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "\n",
        "cd cod_CodeBert/CodeBERT/CodeBERT/code2nl\n",
        "\n",
        "lang=\"java\" #programming language\n",
        "lr=5e-5\n",
        "batch_size=16\n",
        "beam_size=5\n",
        "source_length=256\n",
        "target_length=128\n",
        "data_dir=/mnt/batch/tasks/shared/LS_root/mounts/clusters/teslak80code/code/Users/GUSTAVO.PEREIRA87\n",
        "output_dir=$data_dir/model\n",
        "train_file=$data_dir/codesummarization_data/train/train.jsonl\n",
        "dev_file=$data_dir/codesummarization_data/dev/dev.jsonl\n",
        "eval_steps=500 #400 for ruby, 600 for javascript, 1000 for others\n",
        "train_steps=10000 #20000 for ruby, 30000 for javascript, 50000 for others\n",
        "pretrained_model=microsoft/codebert-base #Roberta: roberta-base\n",
        "\n",
        "python run.py --do_train --do_eval \\\n",
        "--model_type roberta \\\n",
        "--model_name_or_path $pretrained_model \\\n",
        "--train_filename $train_file \\\n",
        "--dev_filename $dev_file \\\n",
        "--output_dir $output_dir \\\n",
        "--max_source_length $source_length \\\n",
        "--max_target_length $target_length \\\n",
        "--beam_size $beam_size \\\n",
        "--train_batch_size $batch_size \\\n",
        "--eval_batch_size $batch_size \\\n",
        "--learning_rate $lr \\\n",
        "--train_steps $train_steps \\\n",
        "--eval_steps $eval_steps | tee -a train_test_metrics.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Process is interrupted.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "id": "XZleUVgssVHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1638812176370,
          "user_tz": 180,
          "elapsed": 1286811,
          "user": {
            "displayName": "Gustavo Flores",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjxNVr_7UdeGpTG8rXW6NPC2VVtbM9-yV2jnccHHg=s64",
            "userId": "07460781209050067384"
          }
        },
        "outputId": "cd405246-1b40-4287-a5d1-7f8916151753"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***** Running evaluation *****\n",
        "12/08/2021 03:15:00 - INFO - __main__ -     Num examples = 8714\n",
        "12/08/2021 03:15:00 - INFO - __main__ -     Batch size = 16\n",
        "12/08/2021 03:21:54 - INFO - __main__ -     eval_ppl = 26.37854\n",
        "12/08/2021 03:21:54 - INFO - __main__ -     global_step = 30000\n",
        "12/08/2021 03:21:54 - INFO - __main__ -     train_loss = 3.056\n",
        "12/08/2021 03:21:54 - INFO - __main__ -     ********************\n",
        "12/08/2021 03:21:59 - INFO - __main__ -     Best ppl:26.37854\n",
        "12/08/2021 03:21:59 - INFO - __main__ -     ********************\n",
        "Total: 1000\n",
        "12/08/2021 03:31:42 - INFO - __main__ -     bleu-4 = 15.29 \n",
        "12/08/2021 03:31:42 - INFO - __main__ -     ********************\n",
        "12/08/2021 03:31:42 - INFO - __main__ -     Best bleu:15.29\n",
        "12/08/2021 03:31:42 - INFO - __main__ -     ********************\n",
        "loss 2.9972: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [26:57:10<00:00,  3.23s/it]\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference and Evaluation"
      ],
      "metadata": {
        "id": "eoMQR_WElANJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "\n",
        "cd cod_CodeBert/CodeBERT/CodeBERT/code2nl\n",
        "\n",
        "lang=\"java\" #programming language\n",
        "beam_size=5\n",
        "batch_size=16\n",
        "source_length=256\n",
        "target_length=128\n",
        "data_dir=/mnt/batch/tasks/shared/LS_root/mounts/clusters/teslak80code/code/Users/GUSTAVO.PEREIRA87\n",
        "output_dir=$data_dir/model\n",
        "dev_file=$data_dir/codesummarization_data/dev/dev.jsonl\n",
        "test_file=$data_dir/codesummarization_data/test/test.jsonl\n",
        "test_model=$output_dir/checkpoint-best-bleu/pytorch_model.bin #checkpoint for test\n",
        "\n",
        "python run.py --do_test \\\n",
        "--model_type roberta \\\n",
        "--model_name_or_path microsoft/codebert-base \\\n",
        "--load_model_path $test_model \\\n",
        "--dev_filename $dev_file \\\n",
        "--test_filename $test_file \\\n",
        "--output_dir $output_dir \\\n",
        "--max_source_length $source_length \\\n",
        "--max_target_length $target_length \\\n",
        "--beam_size $beam_size \\\n",
        "--eval_batch_size $batch_size"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "12/06/2021 16:43:37 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='', dev_filename='/content/drive/MyDrive/codesummarization_data/dev/dev.jsonl', do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=128, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/content/drive/MyDrive/model/checkpoint-best-bleu/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=128, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/content/drive/MyDrive/model', seed=42, test_filename='/content/drive/MyDrive/codesummarization_data/test/test.jsonl', tokenizer_name='', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)\n12/06/2021 16:43:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\nDownloading: 100% 498/498 [00:00<00:00, 559kB/s]\nDownloading: 100% 878k/878k [00:00<00:00, 2.36MB/s]\nDownloading: 100% 446k/446k [00:00<00:00, 1.47MB/s]\nDownloading: 100% 150/150 [00:00<00:00, 166kB/s]\nDownloading: 100% 25.0/25.0 [00:00<00:00, 28.5kB/s]\nDownloading: 100% 476M/476M [00:07<00:00, 67.7MB/s]\n12/06/2021 16:43:52 - INFO - __main__ -   reload model from /content/drive/MyDrive/model/checkpoint-best-bleu/pytorch_model.bin\nTraceback (most recent call last):\n  File \"run.py\", line 524, in <module>\n    main()\n  File \"run.py\", line 266, in main\n    model.load_state_dict(torch.load(args.load_model_path))\n  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n    with _open_file_like(f, 'rb') as opened_file:\n  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n    super(_open_file, self).__init__(open(name, mode))\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/model/checkpoint-best-bleu/pytorch_model.bin'\n"
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-80726a330259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\ncd CodeBERT/CodeBERT/code2nl\\n\\nlang=\"java\" #programming language\\nbeam_size=5\\nbatch_size=128\\nsource_length=256\\ntarget_length=128\\ndata_dir=/content/drive/MyDrive\\noutput_dir=$data_dir/model\\ndev_file=$data_dir/codesummarization_data/dev/dev.jsonl\\ntest_file=$data_dir/codesummarization_data/test/test.jsonl\\ntest_model=$output_dir/checkpoint-best-bleu/pytorch_model.bin #checkpoint for test\\n\\npython run.py --do_test \\\\\\n--model_type roberta \\\\\\n--model_name_or_path microsoft/codebert-base \\\\\\n--load_model_path $test_model \\\\\\n--dev_filename $dev_file \\\\\\n--test_filename $test_file \\\\\\n--output_dir $output_dir \\\\\\n--max_source_length $source_length \\\\\\n--max_target_length $target_length \\\\\\n--beam_size $beam_size \\\\\\n--eval_batch_size $batch_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '\ncd CodeBERT/CodeBERT/code2nl\n\nlang=\"java\" #programming language\nbeam_size=5\nbatch_size=128\nsource_length=256\ntarget_length=128\ndata_dir=/content/drive/MyDrive\noutput_dir=$data_dir/model\ndev_file=$data_dir/codesummarization_data/dev/dev.jsonl\ntest_file=$data_dir/codesummarization_data/test/test.jsonl\ntest_model=$output_dir/checkpoint-best-bleu/pytorch_model.bin #checkpoint for test\n\npython run.py --do_test \\\n--model_type roberta \\\n--model_name_or_path microsoft/codebert-base \\\n--load_model_path $test_model \\\n--dev_filename $dev_file \\\n--test_filename $test_file \\\n--output_dir $output_dir \\\n--max_source_length $source_length \\\n--max_target_length $target_length \\\n--beam_size $beam_size \\\n--eval_batch_size $batch_size' returned non-zero exit status 1."
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "id": "dMGyAtw6lEy2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1638809032956,
          "user_tz": 180,
          "elapsed": 19092,
          "user": {
            "displayName": "Gustavo Flores",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjxNVr_7UdeGpTG8rXW6NPC2VVtbM9-yV2jnccHHg=s64",
            "userId": "07460781209050067384"
          }
        },
        "outputId": "7d6043d2-5413-4747-8c13-91dd5e0a0d56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "# model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "# model.to(device)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "aXAUvhWnkQk0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "CodeBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNFOdrmT4HVjK4+lXEFJ31w"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}